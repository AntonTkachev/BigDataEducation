# BigDataEducation
Data Engineer education tips

## HADOOP

**Hadoop** — свободно распространяемый набор утилит, библиотек и фреймворк для разработки и выполнения распределённых программ, работающих на кластерах из сотен и тысяч узлов.

#### Дистрибутивы Apache Hadoop:
- ClouderaCDH
- Hortonworks
- MapR

**Модули**:
- **HDFS**:
  Распределенная файловая система Hadoop для хранения файлов больших размеров с возможностью потокового доступа к информации.  
  Нерентабельно хранить файлы которые меньше блока на HDFS, (стандартные размеры 64Мб и 128Мб), таким образом если у нас будет файл 40Мб а размер блока 64Мб, то с каждого блока мы будем терять 24Мб, а если у нас таких фалов будет 1000, то потеряем уже 24Гб(а если у нас будет репликация не 1 а 2, то потеряем 48Гб).  
  Кол-во файлов ограничено размерами RAM сервера на котором запущен NameNode.

- **YARN**:
  Диспетчер ресурсов в кластерах Apache Hadoop и Spark, отвечает за выделение ресурсов распределенным приложениям
  Побольше написать???
- **MapReduce**:
  Фреймворк для написания приложений, которые обрабатывают большие объемы данных параллельно.
  Работа MapReduce заключается в разбивке входного набора данных на независимые блоки, которые обрабатываются параллельно.

- **Common**:
  Предоставляет инструменты, необходимые в операционных системах для чтения данных, хранящихся в файловой системе Hadoop.

-------------------------------------------------------------------
**Архитектура**:
- **NameNode(управляющий узел)** — отвечает за открытие и закрытие файлов, создание и удаление каталогов, управление доступом со стороны внешних клиентов.

> **fsimage** - снимок/snapshot системы. где хранятся файлы. все что происходит с датой записывается сюда
> **editlog** - последовательность изменений, внесенных в файловую систему после запуска NameNode
> 
> _editlog_ получает последний снимок файловой системы из _fsimage_, при перезапуске _NameNode_
> _NameNode_ редко перезапускается, поэтому _editlog_ может стать очень большим
>
> Это может вызвать следующие проблемы:
> - Editlog станет очень большим, им будет сложно управлять
> - Перезапуск NameNode займет много времени, так как необходимо объединить множество изменений
> - В случае сбоя мы потеряем огромное количество метаданных, так как fsimage очень старый
> 
> Чтобы решить эту проблему, нам нужен механизм, который поможет уменьшить размер editlog и будет иметь актуальный fsimage.

- **Secondary NameNode** — отвечает за объединение editlogs с fsimage из namenode.
  - Получает _editlogs_ из _NameNode_ и через регулярные интервалы, применяет к _fsimage_
  - Как только у него появляется новый _fsimage_, он копирует его обратно в _NameNode_
  - _Namenode_ будет использовать этот _fsimage_ для следующего перезапуска, что сократит время запуска

- **DataNode(сервер данных)** — это стандартный сервер, на котором хранятся данные. Он отвечает за запись и чтение данных и выполняет команды NameNode.

- **Сlient(пользователь)** — которому предоставляют доступ к файловой системе.

- **Standby NameNode** —

![HDFS architecture](/image/hdfs_arch.png)
-------------------------------------------------------------------
LZO — алгоритм сжатия данных

Iac - подход для управления ЦОД через конфигурационные файлы, а не через ручное редактирование конфигураций

-------------------------------------------------------------------
## Data Warehouse
> Это хранилище разных данных, которые уже отсортированы и преобразованы.  
Хранилище, предназначенное для сбора и аналитической обработки исторических данных организации.
В DWH данные аккумулируют и очищают, формируя единый источник.

#### DWH vs СУБД
DWH предназначено для анализа данных, которые поступают в него с определённой периодичностью — например, ежечасно или ежедневно. Оно разворачивается поверх СУБД и способно быстро обрабатывать большие массивы данных
DWH фактически — инструмент для комплексного анализа данных из множества источников: по определенным заданным параметрам

СУБД в основном предназначены не для аналитики, а для повседневной работы. Информация в них обновляется в реальном времени.

## Data Lake 
> Это репозиторий, в котором хранятся огромные объемы необработанных данных в исходном формате до тех пор, пока они не потребуются.
Каждому элементу данных в озере присваивается уникальный идентификатор, и он помечается набором расширенных тегов метаданных.
Когда возникает деловой вопрос, пользователь может найти и извлечь из озера нужные ему файлы.

### ETL и ELT
Data Warehouse использует метод ETL – Extract, Transform и Load, то есть дословно переводится как «извлечение», «преобразование» и «загрузка».  
Data Lake использует ELT  — Extract, Load и Transform, то есть сначала идет «загрузка», а только потом «преобразование».

**Схема на чтение** — datalake, можно писать что угодно, но когда читаем нужно применять схему, ELT  
**Схема на запись** — datawarehouse(реляционные БД), когда неправильная схема - будет ошибка, ETL

## Типы данных
**Структурированные** — фиксированный формат, известен заранее:
- SQL

**Полуструктурированные** — не вписывается в жесткую структуру, которую требуют реляционные базы данных:
- XML
- JSON
- фото с тегами

**Неструктурированные** — информация представленная в необработанном виде

-------------------------------------------------------------------
## Bronze/Silver/Gold layers

Бронза / Серебро / Золото - это слои в Data Lake, пример как организовать Data Lake:
- Бронза - первичный прием
- Серебро - отфильтрованные и очищенные данные
- Золото - агрегированные данные бизнес-уровня

-------------------------------------------------------------------
## Форматы файлов
https://www.bigdataschool.ru/blog/row-vs-column-file-format-big-data.html
https://luminousmen.com/post/big-data-file-formats

Cтроковые(линейные) форматы (AVRO, Sequence)

Преимущества:
+ MapReduce - данные могут быть использованы независимо друг от друга.
+ Восстановление (есть точки синхронизации)
+ Не являются строго типизированными

Недостатки:
- Скорость чтения (будет считана вся строка)
- Степень сжатия ниже

Колоночно-ориентированных форматы (Parquet, ORC)

Преимущества:
+ Скорость чтения (можно пропускать ненужные столбцы)
+ Степень сжатия выше

Недостатки:
- Занимает больше места в оперативной памяти (поскольку, чтобы получить столбец из нескольких строк, кэшируется каждая строка)
- Восстановление (нет точек синхронизации)

**Sequence File (файл последовательностей)** – это двоичный формат для хранения Big Data в виде сериализованных пар ключ/значение в экосистеме Apache Hadoop, позволяющий разбивать файл на участки при сжатии. Это обеспечивает параллелизм при выполнении задач MapReduce, т.к. разные участки одного файла могут быть распакованы и использованы независимо друг от друга

Преимущества:
+ Более компактны по сравнению с текстовыми файлами – например, 1GB Sequence-файлов с 8 блоками HDFS занимают всего около 3,6 КБ вместо 4,5 МБ для хранения 10 000 объектов в ОЗУ на узле кластера Apache Hadoop
+ 2 типа сжатия файлов – на уровне записи и на уровне блока;
+ Возможность распараллеливания задач за счет независимой распаковки и использования разных порций одного файла;
+ Может выступать в качестве контейнера множества мелких файлов, что позволяет в полной мере использовать оптимизацию HDFS и MapReduce для больших объемов, избежав проблем с одновременной обработкой нескольких файлов

Недостатки:
- Взаимодействовать с форматом можно лишь через Java API
- Формат НЕ является человекочитаемым, что затрудняет отладку

**CSV** - строковый формат, разделенный запятыми. Каждая строка файла является строкой в таблице. CSV содержит строку заголовка, содержащую имена столбцов для данных, в противном случае файлы считаются частично структурированными.

Преимущества:
+ Формат является человекочитаемым и легко редактируется вручную
+ Предоставляет простую схему
+ Может обрабатываться практически всеми существующими приложениями
+ Прост в реализации и синтаксическом анализе
+ Компактен. Для XML запускается тег и заканчивается тег для каждого столбца в каждой строке. В CSV заголовки столбцов записываются только один раз;

Недостатки:
- Позволяет работать с плоскими данными. Сложные структуры данных должны обрабатываться отдельно от формата
- Нет поддержки типов столбцов. Нет разницы между текстовыми и числовыми столбцами
- Не существует стандартного способа представления двоичных данных
- Проблемы с импортом CSV (например, отсутствие разницы между NULL и кавычками)
- Плохая поддержка специальных символов
- Отсутствие универсального стандарта

**JSON** - представлен в виде пар ключ-значение в частично структурированном формате. Может хранить данные в иерархическом формате, читаем пользователем. Часто используются в сетевом общении, особенно с ростом веб-служб на основе REST, из-за маленького размера.

Преимущества:
+ Поддерживает иерархические структуры, упрощая хранение связанных данных в одном документе и представляя сложные связи
+ Большинство языков предоставляют упрощенные библиотеки сериализации JSON или встроенную поддержку сериализации/десериализации JSON
+ Поддерживает списки объектов, помогая избежать хаотичного преобразования списков в реляционную модель данных
+ Широко используемый формат файлов для баз данных NoSQL, таких как MongoDB, Couchbase и Azure Cosmos DB
+ Встроенная поддержка в большинстве современных инструментов

Недостатки:
- Потребляет больше памяти благодаря повторяющимся именам столбцов
- Плохая поддержка специальных символов
- Плохо разделяется
- Не имеет индексации
- Менее компактен по сравнению с двоичными форматами

**Parquet** - представляют собой двоичные файлы, содержащие метаданные об их содержимом, метаданные столбцов для файла Parquet хранятся в конце файла, что обеспечивает быструю однопроходную запись.  
**Parquet** оптимизирован для парадигмы Write Once Read Many (WORM). Он пишет медленно, но читает невероятно быстро, особенно когда вы обращаетесь только к подмножеству столбцов. Паркет является хорошим выбором для тяжелых рабочих нагрузок при чтении частей данных. Для случаев, когда нужно работать с целыми строками данных, следует использовать формат типа CSV или AVRO.

Преимущества:
+ Имеет столбчатый формат. Будут извлекаться/считываться только необходимые столбцы, что уменьшает дисковый ввод-вывод. Концепция называется projection pushdown
+ Схема перемещается вместе с данными, поэтому данные являются самоописывающимися
+ Хотя он предназначен для HDFS, данные могут храниться в других файловых системах, таких как GlusterFs или NFS
+ Это просто файлы, поэтому с ними легко работать, перемещать, создавать резервные копии и реплицировать
+ Встроенная поддержка в Spark позволяет легко взять и сохранить файл в хранилище
+ Обеспечивает очень хорошее сжатие до 75% при использовании даже форматов сжатия, таких как snappy
+ Как показывает практика, этот формат является самым быстрым для процессов с интенсивным чтением по сравнению с другими форматами файлов
+ Хорошо подходит для решений по хранению данных, где требуется агрегация по определенному столбцу над огромным набором данных
+ Также поддерживает predicate pushdown, тем самым снижая дальнейшую стоимость передачи данных из хранилища в механизм обработки для фильтрации

Недостатки:
- Конструкция на основе столбцов заставляет задуматься о схеме и типах данных
- Не всегда имеет встроенную поддержку в инструментах, отличных от Spark
- Он не поддерживает модификацию данных (файлы Parquet неизменяемы) и эволюцию схем. Spark может комбинировать схему, если вы изменяете ее с течением времени, но вы можете изменить что-то в существующем файле, только перезаписав его

**Avro** - строковый формат данных, в котором схема хранится в формате JSON, в то время как данные хранятся в двоичном формате, что минимизирует размер файла и максимизирует эффективность. Avro имеет надежную поддержку эволюции схемы, управляя добавленными, отсутствующими и измененными полями.  
Способность Avro управлять эволюцией схем позволяет обновлять компоненты независимо, в разное время, с низким риском несовместимости.  
Поскольку схема хранится в JSON, а данные хранятся в двоичной форме, Avro является относительно компактным вариантом как для постоянного хранения, так и для передачи.  

Преимущества:
+ Лингвистически нейтральная сериализация данных.
+ Хранит схему в заголовке файла, поэтому данные являются self-describing;
+ Простая и быстрая сериализация и десериализация данных, которые могут обеспечить очень хорошую производительность приема;
+ Как и в случае с файлами Sequence, файлы Avro также содержат маркеры синхронизации для отдельных блоков. Это делает его легко разделяемым;
+ Файлы, отформатированные в Avro, являются разделяемыми и сжимаемыми и поэтому хорошо подходят для хранения данных в экосистеме Hadoop;
+ Схема, используемая для чтения файлов Avro, не обязательно должна совпадать со схемой, используемой для записи файлов. Это позволяет добавлять новые поля независимо друг от друга;

Недостатки:
- Нужно контролировать схему и тип данных
- Формат НЕ является человекочитаемым, что затрудняет отладку
- Не интегрирован под каждый язык программирования.

Avro по сравнению с Parquet:

Avro — формат хранения по строкам, тогда как Parquet хранит данные по столбцам.  
Parquet лучше подходит для аналитических запросов, то есть операции чтения и запрос данных гораздо эффективнее, чем запись.  
Операции записи в Avro выполняются эффективнее, чем в Parquet.  
Avro более зрело работает с эволюцией схем. Parquet поддерживает только добавление схемы, а в Avro реализована многофункциональная эволюция, то есть добавление или изменение столбцов.  
Parquet идеально подходит для запроса подмножества столбцов в многоколоночной таблице. Avro подходит для операций ETL, где мы запрашиваем все столбцы.

ORC по сравнению с Parquet:

Parquet лучше хранит вложенные данные.  
ORC лучше приспособлен к проталкиванию предикатов (predicate pushdown).  
ORC поддерживает свойства ACID.  
ORC лучше сжимает данные.

Примеры использования:
- Линейный формат AVRO обеспечивает высокую скорость записи информации, и потому отлично подходит обработки потоков Big Data в Apache Kafka
- Колоночный формат быстрее считывают данные из файла, поэтому подходит к СУБД на основе Apache Hadoop

-------------------------------------------------------------------
## VM vs Container
**Виртуальная машина (VM)** — это виртуальный компьютер со всеми виртуальными устройствами и виртуальным жёстким диском, на который и устанавливается новая независимая ОС, 
мы получаем абстракцию физического оборудования, позволяющую запускать на одном компьютере множество виртуальных компьютеров.  
Виртуальное оборудование отображается в свойствах системы, а установленные приложения взаимодействуют с ним как с настоящим.   
При этом сама виртуальная машина полностью изолирована от реального компьютера, хотя и может иметь доступ к его диску и периферийным устройствам.  
Запускается на **процессоре**.

**Контейнеры** — обеспечивает виртуализацию на уровне ОС, а не аппаратного обеспечение.  
Такой подход обеспечивает меньший объем занимаемого места на жёстком диске, быстрое развертывание и более простое масштабирование, но меньшую безопасность.  
Контейнеры разделяют **ядро** системы, где каждый из контейнеров работает как отдельный процесс основной ОС.

-------------------------------------------------------------------
## Docker Modules

- **Docker daemon** — осуществляется все взаимодействие с контейнерами: создание и удаление, запуск и остановка
- **Docker client** — интерфейс командной строки для управления Docker daemon. Мы пользуемся этим клиентом, когда создаем и разворачиваем контейнеры, а клиент отправляет эти запросы в Docker daemon.
- **Docker image(образ)** — неизменяемый файл, из которого разворачиваются контейнеры. Приложения упаковываются именно в образы, из которых потом уже создаются контейнеры.
- **Дистрибутив для установки ОС** — это Docker image, а установленная и работающая ОС — это Docker container
- **Docker container** — уже развернутое из Docker image и работающее приложение.
- **Docker Registry** — репозиторий с докер-образами. Разработчики будут размещать там образы, которые будут использоваться всей компанией.
- **Dockerfile** — это инструкция для сборки образа. Это простой текстовый файл, содержащий по одной команде в каждой строке. В нем указываются все программы, зависимости и образы, которые нужны для разворачивания образа.

-------------------------------------------------------------------
## OLTP vs OLAP
**OLTP** (Online Transaction Processing) или реляционные БД- это базы данных, которые используются везде и повсеместно. Их основная цель - ввод/редактирование/удаление данных в режиме онлайн.

**OLAP** (Online Analytical Processing) или многомерные БД - это базы данных, которые служат непосредственно для проведения быстрого анализа больших объемов данных. Обычно такие БД используются для построения аналитической отчетности за большой промежуток времени.

**OLAP** выбирает данные быстрее, чем **OLTP**

**OLTP** придерживаются принципов нормализации, **OLAP** - денормализации.

-------------------------------------------------------------------
## Нормализация/Денормализация

1НФ:
- В каждой клетке таблицы только одно значение
- Не должно быть повторяющихся строк

2НФ:
- 1НФ
- Есть первичный ключ
- Все атрибуты зависят от первичного ключа, а не от какой-то ее части

3НФ:
- 2НФ
- Все атрибуты зависят от первичного ключа, но не от других атрибутов

> Денормализация — поместить избыточные данные туда, где они смогут принести максимальную пользу.  
Логика в том, чтобы снизить время исполнения определенных запросов через упрощение доступа к данным или через создание таблиц с результатами отчетов, построенных на основании исходных данных.

dimensional modeling!! примеры

-------------------------------------------------------------------
## Spark

**Spark** - фреймворк с открытым исходным кодом, для распределённой обработки неструктурированных и слабоструктурированных данных.

**Spark** из-за поддержки системой вычислений в памяти в десятки раз производительнее Hadoop.
Hadoop после каждый итерации записывает в HDFS, Spark - в RAM.
Так же Hadoop всегда используется map-reduce, даже если нужно сделать несколько reduce подряд.

#### Устранение неполадок Spark: https://docs.qubole.com/en/latest/troubleshooting-guide/spark-ts/troubleshoot-spark.html

#### Spark cluster architecture:

- **Driver** – мастер-процесс, который преобразует программы в задачи и планирует их для исполнителей с помощью планировщика задач (Task Scheduler)  
- **Cluster Manager** – ядро фреймворка, которое позволяет запускать исполнители, а иногда и драйверы. Именно здесь планировщик (Scheduler) планирует действия и задания приложения в режиме FIFO, т.е. прямой очереди.  
- **Slave Processes** – сущности, на которых выполняется отдельная задача из задания. Запущенные исполнители работают до завершения жизненного цикла приложения, а в случае отказа перехватывают работу друг друга, чтобы продолжить выполнение задания.  
- **RDD** – это распределенная коллекция неизменяемых наборов данных на разных узлах кластера, разделенная на один или несколько разделов (partition), чтобы добиться параллелизма внутри приложения за счет локальности данных. Преобразования повторного разделения (repartition) или объединения (coalesce) позволяют сохранить количество разделов.  
- **DAG (Directed Acyclic Graph)** – направленный ациклический граф операторов, который генерирует фреймворк, когда пользовательский код введен в консоль. При запуске действия с RDD, фреймворк отправляет DAG в планировщик графов (DAGScheduler), где графы операторов разделяются на этапы задачи (stages). Каждый этап может содержать задания, основанные на нескольких разделах входных данных. DAGScheduler объединяет эти графы операторов в конвейер (pipeline). Например, граф оператора Map составляет граф для одного этапа, который переходит в Планировщик заданий в диспетчере кластеров для их выполнения. Далее эта задача исполняется worker’ом или executor’ом на ведомом устройстве (slave).

#### Apache Spark Internal architecture:
- **Task** – наименьший исполнительный блок в Spark. Task в spark выполняет ряд инструкций. Например: чтение данных, фильтрация и применение map() к данным могут быть объединены в task. Tasks выполняются внутри executor.
- **Stage** – состоит из нескольких tasks, и каждая task на этапе выполняет один и тот же набор инструкций.
- **Job** – состоит из нескольких stages. Когда Spark сталкивается с функцией, требующей перетасовки, она создает новый stage. Функции преобразования, такие как reduceByKey(), Join() итд, вызовут перетасовку и приведут к новому stage. Spark также создаст stage при чтении набора данных.
- **Application** – включает в себя несколько job. Job создается всякий раз, когда вы выполняете функцию действия, такую как write().

### Spark context and Spark session

Точка входа позволяет обмениваться данными с источниками данных и выполнять определенные операции, такие как чтение и запись данных.  

**SparkContext**, **SQLContext** и **HiveContext** точки входа начиная со Spark 1.x  
**SparkSession** точка входа начиная со Spark 2.x, объединяет все прошлые  

-------------------------------------------------------------------
[Можно картинки отсюда взять](https://spark-school.ru/blogs/how-catalyst-works/#:~:text=%D0%A3%D0%B7%D0%BA%D0%B8%D0%B5%20%D0%BF%D1%80%D0%B5%D0%BE%D0%B1%D1%80%D0%B0%D0%B7%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D1%8F%20(Narrow%20transformations)%20%E2%80%94,%D1%81%20%D1%82%D0%B5%D0%BC%20%D0%B6%D0%B5%20%D1%87%D0%B8%D1%81%D0%BB%D0%BE%D0%BC%20%D1%80%D0%B0%D0%B7%D0%B4%D0%B5%D0%BB%D0%BE%D0%B2.)

### Преобразования (Transformations)
Transformations — это функция, которая создает новый RDD из существующего RDD. Он принимает RDD в качестве входного аргумента и создает один или несколько RDD в качестве выходных аргумента.

**Узкие преобразования (Narrow transformations)** — это когда нет перемещения данных между разделами. Преобразование применяется к данным каждого раздела RDD, и создается новый RDD с тем же числом разделов.  
- filter – фильтрация применяется к данным каждого раздела, а полученные данные представляют раздел во вновь созданном RDD.

**Широкие преобразования (Wide transformations)** — требуют перемещения данных между разделами или так называемого перемешивания. Данные перемещаются с целью создания нового RDD.  
- sortBy - сортирует данные на основе определенного столбца и возвращает новый RDD.  

### Action
Action — это функция RDD, результат которого отличен от RDD.

- count()
- collect()
- take(n)
- reduce()
- foreach()

### Shuffle
Shuffle — это механизм, который Spark использует для перераспределения данных между различными исполнителями и даже между компьютерами. 
- gropByKey()
- reducebyKey()
- join()
- groupBy()

Spark Shuffle является дорогостоящей операцией, поскольку она включает в себя:
- Дисковый ввод/вывод
- Включает сериализацию и десериализацию данных
- Сетевой ввод-вывод

-------------------------------------------------------------------
#### Spark join strategy
- Inner Join – выводит только совпавшие по условию соединения объединенные записи из входных наборов данных  
- Outer Join – в дополнение к сопоставленным соединенным записям также выводит несоответствующие записи. Outer Join дополнительно делят на левое, правое и полное, в зависимости от набора входных данных для вывода несовпадающих записей.  
- Semi Join – выводит отдельную запись, принадлежащую только одному из двух входных наборов данных в совпавшем или в несоответствующем экземпляре. Если запись, принадлежащая одному из входных наборов данных, выводится в несоответствующем экземпляре  
- Cross Join – выводит все соединенные записи, которые возможны путем соединения каждой записи из одного набора входных данных с каждой записью другого набора входных данных.

https://www.bigdataschool.ru/wp-content/uploads/2020/12/sqljoin1.png

-------------------------------------------------------------------
> Ленивая оценка - Apache Spark откладывает оценку до тех пор, пока это не станет абсолютно необходимым.

> Это один из ключевых факторов, влияющих на его скорость. Для преобразований Spark добавляет их в вычислительную группу DAG, и только когда драйвер запрашивает некоторые данные, эта группа DAG фактически выполняется.

#### AQE - релиз Spark 3.0
Основная идея AQE состоит в том, чтобы сделать план выполнения не окончательным и перепроверять статус после каждого этапа. Таким образом, план выполнения разбивается на новые абстракции «этапов запроса», разделенных этапами.

Типовые правила применяемые к логическому плану запроса:  
**predicate pushdown** – позволяет оптимизировать запросы Spark SQL, фильтруя данные в запросе к СУБД и уменьшая количество извлекаемых записей. По умолчанию Spark Dataset API автоматически передает действительные WHERE-условия в базу данных.  
**partition pruning** – убирает из рассмотрения партиции, не удовлетворяющие фильтру.

#### .repartition() and .coalesce()
Методы разделяющие DataFrame на части  
**repartition** – на примерно одинаковые, может уменьшать или увеличивать число разделов  
**сoalesce** – на разного размера, может только уменьшать кол-во разделов, быстрее без Shuffle???

-------------------------------------------------------------------
#### .cache() vs .persist()
Для кэширования данных в Apache Spark применяется методы cache или persist.
**cache** – кеширует в оперативной памяти,
**persist** – на выбор в зависимости от переданного аргумента.  
Хорошее правило: определите DataFrame, который вы будете повторно использовать в своем приложении Spark, а затем произведите кэширование.

**Зачем?**  
- Повторное использование данных.  
- Аналог контрольной точки.  
- Читать с локального диска быстрее чем из удаленного источника.

**persist аргументы:**
- DISK_ONLY: данные сохраняются на диске в сериализованном формате
- MEMORY_ONLY: данные сохраняются в оперативной памяти в десериализованном формате
- MEMORY_AND_DISK: данные сохраняются в оперативной памяти, и если памяти недостаточно, вытесненные блоки будут сохранены на диске
- OFF_HEAP: данные сохраняются в памяти вне кучи
- MEMORY_ONLY_SER - Использование сериализованного формата увеличит время обработки, но уменьшит объем памяти.
- DISK_ONLY_2, MEMORY_AND_DISK_2 - Использование репликации

-------------------------------------------------------------------
## Broadcast Variables (Распределённые переменные)
Переменные, которые используются для создания копии данных и сохранения ее на всех узлах кластера. Broadcast Variables позволяют эффективно передавать большие значения, доступные только для чтения, всем рабочим узлам для дальнейшего использования в операциях Spark  
Создание Broadcast Variables полезно, когда задачам на нескольких этапах требуются одни и те же данные или когда важно кэширование данных в десериализованной форме.

Пример создания Broadcast Variables:
```
val broadcastVar = sc.broadcast(Array(1, 2, 3))

broadcastVar.value
// returns [1, 2, 3]
```

-------------------------------------------------------------------
#### RDD vs DF vs DS
- RDD — представление данных в объектном формате  
RDD — это набор объектов Java или Scala, представляющих данные.  
Отказоустойчив — если узел, удерживающий раздел, выходит из строя, другой узел берет данные.  
- DataFrame — это распределенная коллекция данных, организованных в именованные столбцы. Концептуально она равна таблице в реляционной базе данных.  
- DataSet — type-safe/ быстрее RDD, но медленнее DataFrame/доступен только в Scala/Java  
***
- RDD — структурированными\неструктурированными данными\схему нужно указать пользователю\heap
- DataFrame — структурированными\полуструктурированными\схема определяется автоматически\
- DataSet — структурированные\неструктурированные данные\схема определяется\
***
ГДЕ ХРАНЯТСЯ?

|                        | RDDs                                                                                                        | DataFrame                                                                                                                  | DataSet                                                                                                           |
|------------------------|-------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------|
| Представление данных   | RDD — это распределенная коллекция элементов данных без какой-либо схемы.                                   | Это также распределенная коллекция, организованная в именованные столбцы.                                                  | Это расширение DataFrame с большим количеством функций, таких как type-safe и объектно-ориентированный интерфейс. |
| Оптимизация            | Нет встроенного механизма оптимизации. Разработчикам необходимо писать оптимизированный код самостоятельно. | Используется catalyst для оптимизации.                                                                                     | Используется catalyst для оптимизации.                                                                            |
| Схема                  | Схему нужно определять вручную                                                                              | Схема определяется автоматически.                                                                                          | Aвтоматически узнает схему набора данных с помощью SQL Engine.                                                    |
| Операции агрегирования | RDD медленнее, чем DataFrame и DataSet, для выполнения простых операций, таких как группировка данных.      | Он предоставляет простой API для выполнения операций агрегирования. Он выполняет агрегирование быстрее, чем RDD и DataSet. | DataSet быстрее, чем RDD, но немного медленнее, чем Dataframes.                                                   |

-------------------------------------------------------------------
## Spark memory model

### Spark Catalyst 
Встроенный оптимизатор структурированных запросов в Spark SQL.

1. Создает дерево для неразрешенного(нет информации о типах данных) логического плана.  
2. Начинает применять к нему правила, пока не разрешит все ссылки на атрибуты и отношения.  
3. Применяет все правила оптимизации к логическому плану, оптимизирует затраты.  
4. Генерирует несколько физических планов на основе логического плана для выбора наиболее эффективного.  
5. Генерация кода.

### Tungsten

> Используется в DataSet, DataFrame  
Благодаря инструменту Tungsten не требуется использовать сериализацию Java для кодирования данных.  
Tungsten реализует собственный формат сериализации, называемого небезопасной строкой (UnsafeRow). Он быстрее и компактнее Kryo и сериализация Java.

-------------------------------------------------------------------
## Spark streaming

**Spark streaming** 
— это расширение основного API Spark, которое обеспечивает масштабируемую, высокопроизводительную и отказоустойчивую потоковую обработку потоков данных в реальном времени. 
Данные могут поступать из многих источников, таких как: Kafka, Kinesis или TCP, и могут обрабатываться с использованием сложных алгоритмов, выраженных с помощью высокоуровневых функций.
Наконец, обработанные данные могут быть отправлены в файловые системы, базы данных и интерактивные панели мониторинга. Фактически, вы можете применять алгоритмы машинного обучения и обработки графов Spark к потокам данных.

Архитектура:
- **Engine** – обрабатывает SQL-операторы и запросы. Пользователю просто определяет логику своего приложения, записывая SQL-операторы, а движок сам создает и
  запускает приложение на доступных серверах ksqlDB, работая на каждом экземпляре сервера. Движок, реализованный реализован в классе KsqlEngine.java,
  сам анализирует пользовательские операторы SQL и строит соответствующие топологии Kafka Streams.
- **REST-интерфейс для клиентского доступа к движку** – позволяет взаимодействовать с механизмом ksqlDB из интерфейса командной строки,
  Confluent Control Center или любого другого клиента REST. REST-сервер ksqlDB реализован в классе KsqlRestApplication.java.
- **Интерфейс командной строки (CLI)** – консоль для взаимодействия с экземплярами сервера и разработки потоковых приложений.
- **Пользовательский интерфейс ksqlDB** –  позволяет разрабатывать приложения ksqlDB в Confluent Control Center и Confluent Cloud.

**Spark Watermark** — это пороговое значение, указывающее, как долго система ожидает поздних событий. Если поступающее событие находится внутри водяного знака, оно используется для обновления запроса. В противном случае, если он старше водяного знака, он будет удален и не будет дополнительно обработан потоковым движком.

**Spark Checkpointing** — восстановление системы хранения после сбоев:
- **Контрольные точки метаданных:** используются для восстановления узла драйвера потокового приложения после сбоя.
  Он включает в себя конфигурации, используемые для создания приложения, операции DStream и неполные пакеты.
- **Контрольные точки данных:** При потоковой передаче с отслеживанием состояния созданные RDD сохраняются в хранилище, например HDFS.
  Это тот случай, когда предстоящий RDD для некоторых преобразований зависит от предыдущих RDD. В этом случае длина цепочки зависимостей со временем продолжает увеличиваться.
  Таким образом, чтобы избежать увеличения времени восстановления, промежуточные RDD периодически блокируются в некотором надежном хранилище.

**KStream / KTable**  
KTable разделяет данные между всеми запущенными экземплярами Kafka Streams, в то время как GlobalKTable содержит полную копию всех данных в каждом экземпляре.  
Недостатком GlobalKTable является то, что ей, очевидно, требуется больше памяти.  
Преимущество заключается в том, что вы можете выполнить соединение KStream-GlobalKTable с неключевым атрибутом из потока.

**ksqlDB** можно рассматривать в качестве своего рода надстройки над Kafka Streams,
поскольку этот инструмент позволяет преобразовать SQL-запросы для потоковой аналитики больших данных, в распределенные приложения.

#### Output modes:

**Append Output Mode**  .outputMode("append")  
Режим вывода, в котором в приемник будут записаны только новые строки в потоковом наборе данных.

**Complete Output Mode**  .outputMode("complete")  
Режим вывода, в котором все строки в потоковом наборе данных будут записываться в приемник каждый раз, когда будут какие-то обновления.

**Update Output Mode**  .outputMode("update")  
Режим вывода, в котором только строки, которые были обновлены в потоковом наборе данных, будут записываться в приемник каждый раз, когда будут какие-то обновления.

-------------------------------------------------------------------
## Spark SQL
Модуль фреймворка Spark для структурированной обработки распределенных данных, позволяющий выполнять запросы на языке SQL.
Spark SQL использует dataframe для работы с данными. Spark SQL поддерживает загрузку данных из различных внешних источников (Hive, JSON, Avro) для формирования dataframe.
Spark SQL не зависит от языка программирования, поэтому определять интерфейс языка программирования (например, Java, Python, Scala или R).

Свойства Spark SQL:
- Интеграция – Spark SQL может запрашивать данные с помощью SQL-запросов из различных СУБД (MySQL, MS SQL Server, Oracle, Hive) в виде распределенной коллекции данных (Resilient Distributed Dataset, RDD)
- Универсальный доступ к данным – работа со всеми источниками данных происходит по одной и той же схеме, так как доступ к данным обеспечивается посредством механизма SQL-запросов
- Источники данных – Spark SQL поддерживает работу с различными файловыми источниками (JSON, CSV, Parquet). Существует также возможность смешивать данные из различных источников

Архитектуру:
- Программный API (Application Program Interface) – Spark SQL поддерживает работу в таких языках программирования, как Java, Python, Scala и R, предоставляя методы и функции для работы с данными
- SchemaRDD – таблица для временного (промежуточного) хранения данных, которая используется для работы с SQL-запросами при разработке приложений на языках Python, Java, Scala или R. SchemaRDD также позволяет задавать необходимые типы данных для создания DataFrame на основе этих данных

-------------------------------------------------------------------
## Spark ML

Типы обучения:
- Контролируемое обучение(Supervised learning)
- Обучение без присмотра(Unsupervised learning)
- Полуконтролируемое обучение(Semi-supervised learning)
- Обучение с подкреплением(Reinforcement learning) - сообщают машине, какой шаг правильный, а какой нет

Общие шаги типичного решения для машинного обучения:
- Разработка функций
- Обучение модели
- Оценка модели - тут проверяют точность сформированной модели и отсутствие переобученности

-------------------------------------------------------------------
## GraphX ???
Для задач графовой аналитики в Apache Spark есть специальный модуль GraphX, который представляетс собой API для графов и параллельных вычислений. Он расширяет Spark RDD, вводя новую абстракцию Graph

-------------------------------------------------------------------
## Databricks
> Фреймворк Databricks предоставляет среду для хранения и обработки данных.  
> Databricks позволяет создавать код, используя множество языков, в одном процессе.

Платформа Databricks состоит из нескольких слоев:

#### Delta Lake
- Совместимость с Spark API
- Данные хранятся в столбцовом формате Apache Parquet
- Схема данных
- Эволюция схемы

#### Delta Engine
Оптимизированная система обработки запросов для работы с данными, хранящимися в Delta Lake.

#### Data Lakehouse
Aрхитектура управления открытыми данными, которая сочетает в себе гибкость, экономическую эффективность и масштаб DataLake с управлением данными и транзакциями ACID в хранилищах данных, обеспечивая бизнес-аналитику (BI) и машинное обучение (ML) для всех данных.

-------------------------------------------------------------------
## KAFKA

**Apache Kafka** - это распределенная платформа потоковой передачи событий с открытым исходным кодом

**Admin Client** - полезен, когда требуется выполнять некоторые административные команды из клиентского приложения без использования инструментов CLI и GUI для управления Kafka.

maintein ability

!!! как именно консюмер читает сообщения


consumer group - партиции в топиках делятся между потребителями в группе

compacted topic - хранится по одному значению в партиции, значения удаляются по ключу и оставляют самое позднее с таким ключом.

Балансировка нагрузки kafka\Consumer Load Balancing

### Оптимизация

-------------------------------------------------------------------
**Kafka compression** - сжатие данных с помощью различных кодеков – gzip/snappy
Минус оптимизации - увеличение загрузки ЦП на стороне потребителя за счет распаковки сжатых данных.

**Kafka Producer Batch** - объединение нескольких сообщений в пакет для отправки брокеру

-------------------------------------------------------------------
Kafka acks - указывает, сколько подтверждений должен получить продюсер, чтобы запись считалась доставленной брокеру

- 0, когда producer вообще не ждет никакого подтверждения, а сообщение считается в любом случае отправленным.
- 1, когда отправленное сообщение записывается в локальный журнал одного брокера в кластере Кафка (лидер, leader), не ожидая полного подтверждения от всех остальных серверов
- -1 или all, когда producer ждет полной репликации сообщения по всем серверам кластера, что обеспечивает надежную защиту от потери данных, но увеличивает задержку (latency) и снижает пропускную способность.

Consumer Delivery Semantics:

- хотя бы 1 раз (at least once), когда отправитель сообщения получает подтверждение от брокера Kafka при значении параметра acks=all, что гарантирует однократную запись сообщения в топик Kafka. Но если отправитель не получил подтверждения по истечении определенного времени или получил ошибку, он может повторить отправку. При этом сообщение может быть дублировано, если брокер дал сбой непосредственно перед отправкой подтверждения, но после успешной записи сообщения в топик Kafka.
- не более 1-го раза (at most once), когда отправитель не повторяет отправку сообщения при отсутствии подтверждения или в случае ошибки. При этом возможна ситуация, что сообщение не записано в топик Кафка и не получено потребителем. На практике в большинстве случаев сообщения будут доставляться, но иногда возможна потеря данных.
- строго однократно (exactly once), когда даже при повторной попытке отправителя отправить сообщение, оно доставляется строго один раз. В случае ошибки, заставляющей отправителя повторить попытку, сообщение будет однократно записано в логе брокера Kafka. Это избавляет от дублирования или потери данных из-за ошибок на стороне producer’a или брокера Кафка. Чтобы включить эту функцию для каждого раздела следует задать свойство идемпотентности в настройках отправителя idempotence=true. Напомним, идемпотентной считается операций, которая при многократном выполнении даёт тот же результат, что и при однократном.

commitSync - блокирует поток до тех пор, пока не будет встречен либо коммит успешно, либо неустранимая ошибка  
commitAsync - встреченные ошибки либо передаются в callback (если он предусмотрен) или отбрасываются

sync/in-sync - синхронизованная с лидером???

**Kafka Connect** предназначен для перемещения данных между Kafka и другими хранилищами данных.
- worker — инстанс/сервер Kafka Connect
- connector — Java class + пользовательские настройки
- task — один процесс connector'a

-------------------------------------------------------------------
## CAP

C (consistency) — согласованность. Каждое чтение даст вам самую последнюю запись.  
A (availability) — доступность. Каждый узел (не упавший) всегда успешно выполняет запросы (на чтение и запись).  
P (partition tolerance) — устойчивость к распределению. Даже если между узлами нет связи, они продолжают работать независимо друг от друга.  

**НО** можно выбрать только 2 из 3-х свойств:

**Postgresql**

Репликация Master-Slave — одно из распространенных решений
Синхронизация с Master в асинхронном / синхронном режиме
Система транзакций использует двухфазный коммит для обеспечения consistency
Если возникает partition, вы не можете взаимодейстовать с системой (в основном случае)

Таким образом, система не может продолжать работу в случае partition, но обеспечивает strong consistency и availability. Это система **CA**!

**MongoDB**

MongoDB обеспечивает strong consistency, потому что это система с одним Master узлом, и все записи идут по умолчанию в него.
Автоматическая смена мастера, в случае отделения его от остальных узлов.
В случае разделения сети, система прекратит принимать записи до тех пор, пока не убедится, что может безопасно завершить их.

Таким образом, система может продолжать работу в случае разделения сети, но теряется CAP-availability всех узлов. Это **CP** система!

-------------------------------------------------------------------
## RDBMS vs NoSQL

**Реляционная база данных (SQL)** — база, где данные хранятся в формате таблиц, они строго структурированы и связаны друг с другом. В таблице есть строки и столбцы, каждая строка представляет отдельную запись, а столбец — поле с назначенным ей типом данных. В каждой ячейке информация записана по шаблону.

Преимущества SQL — соответствия базы данных требованиям ACID, целостность данных, структурированность.

Недостатки SQL:
- реляционные базы плохо масштабируются, с ними крайне сложно создавать распределенные хранилища
- проектирование крупных баз с множеством компонентов требует значительных усилий. Это приведение сущностей к нормальным формам и сложности в отображении связей типа многие-ко-многим. Такие схемы тяжело читать и понимать их бизнес-применение
- эволюция схемы данных почти всегда отстает от новых потребностей бизнеса. Миграция на обновленную схему занимает много времени, в течение которых сервер недоступен

**Нереляционная база данных (NoSQL)** — хранит данные без четких связей друг с другом и четкой структуры. Вместо структурированных таблиц внутри базы находится множество разнородных документов, в том числе изображения, видео и даже публикации в социальных сетях. В отличие от реляционных БД, NoSQL базы данных не поддерживают запросы SQL.

Преимущества NoSQL — скорость обработки данных, масштабируемость, распределённость систем.

-------------------------------------------------------------------
## CICD

![CICD](/image/CICD.png)
-------------------------------------------------------------------
## ELK stack

https://gitinsky.com/elkstack

E (Elasticsearch) —  
L (Logstash) —  
K (Kibana) — 

> Этот набор компонентов обеспечивает удобное централизованное логирование (ведение журналов) с разных серверов. ELK stack позволяет надежно и безопасно получать данные из любого источника во всех форматах и работать с этими данными: осуществлять поиск по ним, анализировать и визуализировать их в режиме real-time.

-------------------------------------------------------------------
## Oozie 

Oozie веб-приложения, которое позволяет создавать сложные преобразования данных, объединяя обработку разнообразных задач и потоков работ.  

-------------------------------------------------------------------
## NiFi

Apache NiFi — это простая платформа обработки событий, предоставляющая возможности управления потоками данных из разнообразных источников в режиме реального времени с использованием графического интерфейса.

Apache NiFi использует концепцию потока, рассматриваемую как последовательность операций: передача, преобразование и обогащение данных над последовательностью отдельных событий (events). Таким образом, поток НЕ рассматривается как большая пакетная (batch) операция, требующая выполнения первоначальной загрузки всех данных  перед началом обработки. Например, SQL база данных с миллионами строк рассматривается Apache NiFi как миллионы отдельных строк, требующие своей обработки.

Apache NiFi состоит из 3-х основных компонент:
- Flow Files — потоки файлов. Информация в NiFi состоит из двух частей: атрибуты и контейнер с данными (payload). FlowFiles обычно использует предопределенный набор атрибутов, которые могут быть добавлены (изменены) с помощью дополнительных операций. Payload (данные) представляют собой собственно информацию, которая обрабатывается процессорами.
- Flow File Processor — фрагменты кода, представляющие контейнер процессора с входами и выходами для данных. Например, процессор GetFTP получает данные с FTP-директории и создает поток файлов FlowFile, включающий атрибуты  из директории (время создания, имя файла, данные). Полученный FlowFile далее может быть обработан другим процессором, который использует логику на основе атрибутов каждого FlowFile, таких как регулярные выражения Regex,  работающие с именем файла.
- Connections — определение того, как FlowFiles передаются между процессорами. Потоки файлов, обработанные без сбоев, формируют выполненную очередь (success queue), а сообщения с проблемами обработки передаются в failure queue. Существуют и другие типы соединений.
NiFi


Apache NiFi имеет богатый графический веб-интерфейс для создания и управления потоками  данных, более 260 процессоров и коннекторов из коробки, что позволяет его использовать  для сопряжения практически с любыми типами источников и потребителей данных. Асинхронный режим работы обеспечивающий высокую пропускную способность, удобную обработку ошибок и возможность  версионного контроля компонент Apache NiFi.

-------------------------------------------------------------------
## Airflow
Airflow: use cases, basic architecture, DAG, scheduler, executors, operators, sensors!!!

https://habr.com/ru/company/vk/blog/339392/

**DAG** — это смысловое объединение ваших задач, которые вы хотите выполнить в строго определенной последовательности по определенному расписанию. Airflow представляет удобный web-интерфейс для работы с DAG’ами и другими сущностями.

**Operator** — это сущность, на основании которой создаются экземпляры заданий, где описывается, что будет происходить во время исполнения экземпляра задания. Примеры:

- BashOperator — оператор для выполнения bash-команды.
- PythonOperator — оператор для вызова Python-кода.
- EmailOperator — оператор для отправки email’а.
- HTTPOperator — оператор для работы с http-запросами.
- SqlOperator — оператор для выполнения SQL-кода.
- Sensor — оператор ожидания события (наступления нужного времени, появления требуемого файла, строки в базе БД, ответа из API — и т. д., и т. п.).

**Scheduler** в Airflow построен на Celery. Celery — это Python-библиотека, позволяющая организовать очередь плюс асинхронное и распределенное исполнение задач. Со стороны Airflow все задачи делятся на пулы. Пулы создаются вручную. Как правило, их цель — ограничить нагрузку на работу с источником или типизировать задачи внутри DWH. Пулами можно управлять через web-интерфейс:

**Execution Date** — в зависимости от расписания работы DAG’а создаются экземпляры задач на каждую Execution Date. И за каждую Execution Date задачи можно выполнить повторно — или, например, DAG может работать одновременно в нескольких Execution Date.

-------------------------------------------------------------------
## [TEZ](https://www.bigdataschool.ru/blog/tez-vs-spark-what-to-choose-for-hive.html#:~:text=%D1%83%D0%BD%D0%B8%D0%B2%D0%B5%D1%80%D1%81%D0%B0%D0%BB%D1%8C%D0%BD%D0%BE%D1%81%D1%82%D1%8C%20%E2%80%93%20%D0%B1%D0%BB%D0%B0%D0%B3%D0%BE%D0%B4%D0%B0%D1%80%D1%8F%20%D1%88%D0%B8%D1%80%D0%BE%D0%BA%D0%BE%D0%BC%D1%83%20%D0%BD%D0%B0%D0%B1%D0%BE%D1%80%D1%83%20%D0%B2%D0%BE%D0%B7%D0%BC%D0%BE%D0%B6%D0%BD%D0%BE%D1%81%D1%82%D0%B5%D0%B9,%D1%81%D0%BF%D0%B5%D1%86%D0%B8%D0%B0%D0%BB%D0%B8%D0%B7%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%BD%D1%8B%D0%BC%20%D0%B8%D0%BD%D1%81%D1%82%D1%80%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D0%BE%D0%BC%20%D0%B4%D0%BB%D1%8F%20%D1%82%D0%BE%D1%87%D0%B5%D1%87%D0%BD%D1%8B%D1%85%20%D0%BF%D1%80%D0%B8%D0%BB%D0%BE%D0%B6%D0%B5%D0%BD%D0%B8%D0%B9)

-------------------------------------------------------------------

[//]: # (Data locality???)
[//]: # (Parquet)

[//]: # (http://blog.madhukaraphatak.com/secondary-namenode---what-it-really-do/)

[//]: # (https://bitworks.software/2018-08-07-hadoop-cluster-setup-with-hdfs-ha.html)

[//]: # (https://www.lifewire.com/what-does-seek-time-mean-2626007)

[//]: # (Small files problem)

[//]: # (TF/IDF)

[//]: # ()
[//]: # (Elastic X-Pack)

[//]: # ()
[//]: # (No SQL Types &#40;wide column, key-value, document, graph&#41;. Typical use cases and limitations. Mongo, Hbase, Cassandra, Redis)

[//]: # ()
[//]: # (Spark optimizations: data structures, data locality, shared variables)

[//]: # ()
[//]: # (ML Types. ML Flow, tracking, modeling, registry)

[//]: # ()
[//]: # (operations under Delta tables)

[//]: # ()
[//]: # (Schema enforcement and evolution)

[//]: # ()
[//]: # (Kafka Streams: Stream partitions, thread model, local state store, windowing, types of windows &#40;Session; Tumbling; Sliding&#41;)

